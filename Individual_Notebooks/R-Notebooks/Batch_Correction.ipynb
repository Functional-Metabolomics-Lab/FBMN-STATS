{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa786320-bf20-4965-94ae-b7e5e4b380cf",
   "metadata": {},
   "source": [
    "<font size=4> <i>Script in progress </i></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21a340-b9f7-411c-ad05-09cae1007ddb",
   "metadata": {},
   "source": [
    "Assuming the user for this notebook has already used the Stats Notebook (Performing basic uni- and multivariate statistical analsysis of untargeted metabolomics data) [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Functional-Metabolomics-Lab/Statistical-analysis-of-non-targeted-LC-MSMS-data/blob/main/Stats_Untargeted_Metabolomics.ipynb), we will proceed with loading in necessary files and perform Batch Correction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c25f6-9029-48ad-a9e2-daf5875984e4",
   "metadata": {},
   "source": [
    "# Setting a Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f592527-4be0-43fb-ba8d-cd48fe4b35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of the folder with input files:  C:\\Users\\abzer\\OneDrive\\Documents\\GitHub\\Statistical-analysis-of-non-targeted-LC-MSMS-data\\data\n"
     ]
    }
   ],
   "source": [
    "Directory <- normalizePath(readline(\"Enter the path of the folder with input files: \"),\"/\",mustWork=FALSE)\n",
    "setwd(Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989d436e-4d9e-4637-aacf-aca08862e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20221102_SD_BeachSurvey_batchFile.xml\"                \n",
      "[2] \"20221125_Metadata_SD_Beaches_with_injection_order.txt\"\n",
      "[3] \"2023-03-02_Ft_md_merged.csv\"                          \n",
      "[4] \"DB_analog_result_FBMN.tsv\"                            \n",
      "[5] \"SD_BeachSurvey_GapFilled_quant.csv\"                   \n"
     ]
    }
   ],
   "source": [
    "file_names <- list.files('.') #list all the files in the working directory (mentioned by 'dot symbol')\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9598874f-7cad-49bb-8495-df1721402364",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_merged <- read.csv(file_names[3], header = T, check.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0c1f7-ed2a-4865-b8f2-ce8524f9bc63",
   "metadata": {},
   "source": [
    "# <font color ='darkblue'> 1. Batch Correction</font>\n",
    "<a id=\"batch_corr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091c0c4-66e6-4318-ab64-63f8cb1c9301",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> A 'Batch' is a group of samples processed and analyzed by the same experimental & instrumental conditions in the same short time period. In general, if we have more samples than the tray size, we might measure them as multiple batches or groups. When arranging samples in a batch for measurement, in order to ensure biological diversity within a batch, in addition to our samples of interest, it is advised to have QCs, blanks, and controls (Wehrens et al., 2016). To merge data from these different batches, we must look for batch-effects, both, between the batches and within each batch and correct these effects. <br> <b>But, prior to batch correction on a dataset, we should evaluate the severity of the batch effect and when it is small, it is best to not perform batch correction as this may result in an incorrect estimation of the biological variance in the data. Instead, we should treat the statistical results with caution (Nygaard et al., 2016). For more details, please read the manuscript </b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89a97e-b5c4-4369-9cab-fab7a31e476a",
   "metadata": {},
   "source": [
    "## 1.1. Inter-batch correction:\n",
    "<a id=\"inter_batch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24147e92-6447-4aac-939f-1e1e1140b332",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> In this tutorial, the test dataset was utilized to evaluate the chemical impacts of a significant rain event that occurred in northern San Diego, California (USA) during the Winter of 2017/2018. Despite the presence of a \"ATTRIBUTE_Batch\" column in the metadata, the 3 groups mentioned are not considered as batches due to their distinct collection conditions. The \"ATTRIBUTE_time_run\" column indicates that the seawater samples were collected and measured at different times during Dec 2017, Jan 2018 (after rainfall), and Oct 2018, respectively. Therefore, searching for inter-batch effects is not meaningful since these are 3 distinct groups and were not measured at the same time. </p>\n",
    "\n",
    "<font color=\"red\">If the user is dealing with different batches, they can perform inter-batch correction using the following steps:</font>\n",
    "    \n",
    "1. Calculate the <b>overall mean</b> of each feature \n",
    "2. Calculate the mean of each feature for each batch referred as &rarr; <b>Batchwise feature-mean</b>\n",
    "3. The feature intensities in each batch are then divided by the <b>batchwise feature-mean</b> and multiplied by the <b>overall mean</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be57f5-0443-415d-9892-04fc40f85779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the filename & batch info column along with all feature intensity columns\n",
    "ft_merged2 <- ft_merged %>% select(`filename`,`ATTRIBUTE_Batch`,starts_with(\"X\")) \n",
    "head(ft_merged2,n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa4b997-22d9-424a-89af-e6e8cf5bad92",
   "metadata": {},
   "source": [
    "Now, we can continue with the batch correction steps. <br>\n",
    "\n",
    "<b> Step 1: Calculate the overall mean of each feature: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e17008-ad1f-44ab-b5e1-4d4824295db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm <- as.data.frame(rbind(colMeans(ft_merged2[,-(1:2)]))) #getting the columnwise mean for ft_merged2 except its 1st 2 columns\n",
    "head(fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f4f21-f067-401c-99db-dc525c069168",
   "metadata": {},
   "source": [
    "<b>Step 2: Getting batchwise feature-mean</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c782ab-5745-41e9-9111-a5e50ecd108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm <- ft_merged2[,-1] %>%  #excluding filename column as we are geting only batchwise mean value\n",
    "group_by(`ATTRIBUTE_Batch`) %>%  # grouping them by Batch\n",
    "summarise_all(mean) %>% # getting column-wise mean\n",
    "column_to_rownames('ATTRIBUTE_Batch') %>%\n",
    "as.data.frame() # storing it as dataframe\n",
    "\n",
    "bm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233d021-d01e-4f53-9477-ad07588ab743",
   "metadata": {},
   "source": [
    "We can also get the 'ft_merged2' dataframe split into batchwise dataframes using 'group_split' function. It returns a list with each element as a batch-specific dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54963656-53aa-4200-9cb3-f80cd0442d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df <- ft_merged2 %>%\n",
    "group_split(`ATTRIBUTE_Batch`) %>% #group_split splits & stores the batchwise info as individual dataframes inside a list\n",
    "lapply(., function(x) { # lapply applies the below function to each element within the list created by the previous step \n",
    "    x <- column_to_rownames(x,'filename') # then, we make \"filename\" as the rownames of each dataframe within the list\n",
    "}) \n",
    "\n",
    "sapply(batch_df, dim) # gives the dimension of each list element columnwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0386d-6e01-40a2-98b1-09604a619eb1",
   "metadata": {},
   "source": [
    "The above output shows that there are 3 dataframes inside 'batch_df' list, each with dimension of 62 rows and 11218 columns. Lets look at the 1st dataframe inside batch_df. It contains the 'Batch 1' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5170b2-2c51-4f9a-acd6-8ea10dfb201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(batch_df[[1]],n=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab6829-7e56-456d-8dc5-1f0f4b85a409",
   "metadata": {},
   "source": [
    "<b>Step 3: Correcting for inter-batch effect:</b> <br>\n",
    "Here, the feature intensities in each batch within the batch list are then divided by the <b>batchwise feature-mean</b> and multiplied by the <b>overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5bad95-aac3-4e6d-b72c-00e502248e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib <- list() # creating an empty list for storing inter-batch corrected data\n",
    "\n",
    "for (i in 1:length(batch_df)){\n",
    "    ib[[i]] <- sweep((batch_df[[i]][,-1]), 2, as.numeric(bm[i,]+1), \"/\") #dividing each batch dataframe by batchwise feature-mean\n",
    "    ib[[i]] <- sweep(ib[[i]], 2, as.numeric(fm+1), \"*\") # multiplying by overall mean\n",
    "}\n",
    "\n",
    "ib <- bind_rows(ib) #binding all the list elements together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25709eca-49df-4344-b528-7285e1be1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(ib,n=2)\n",
    "dim(ib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1483bd-1659-4fff-b43e-d4111628ba35",
   "metadata": {},
   "source": [
    "## 1.2. Intra-batch correction:\n",
    "<a id=\"intra_batch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e851b-6716-422c-a553-89deabf017ce",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> <b>It is important to have pooled QC samples or some Internal Standards to correct for intra-batch effects</b>. In case of not having pooled QCs, one can still look for intra-batch effect by visualizing the housekeeping features across the injection order or run time. For the test data used here, some components typically found in the DOM samples as mentioned in the study by <a href=\"https://doi.org/10.1016/j.chemosphere.2020.129450\">Petras et al</a> are: Dibutyl phthalate, pheophorbide A and tryptophan. We will look at the feature 'tryptophan' to see if there is any intensity drift observed along the run time or injection order. However, we cannot correct the effect with housekeeping features, this can only be done with QCs. In such cases, it is better to not correct the effect and treat the data cautiously during statistical analyses. However, normalizing the data, in general, accounts for batch-correction to a certain extent.<font color=red> {insert ref} </font> </p>\n",
    "\n",
    "- <font color = \"red\"> Say how you can perform intra-batch usually with QCs?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208283e3-f415-4598-9613-8c01ef763874",
   "metadata": {},
   "source": [
    "<b> Visualizing within-batch effect using housekeeping features:</b> <br>\n",
    "Since, we have the annotations combined with our column names. we can look for column names of ft_merged with 'tryptophan':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716fb8a-bc07-4763-b348-e1ab1e3a3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grep(\"tryptophan\",colnames(ft_merged),ignore.case=TRUE,value=TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49922687-7293-4b70-a6e4-0dbdcf046534",
   "metadata": {},
   "source": [
    "The molecular weight of tryptophan is 204.22 g/mol. Here, we see tryptophan peaks (~205 m/z) with 2 different RTs. In the column names, we have the libraryID_RT_mz_Annotation. We will choose the feature with higher retention time (row ID 7683) to plot against the injection order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b36f77-9345-4af8-a901-0f3045e6de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "which(colnames(ft_merged) == grep('X7683',colnames(ft_merged),value = TRUE)) # gets the column number of tryptophan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675b698-e44c-4e8c-b7c5-b5084ceeede6",
   "metadata": {},
   "source": [
    "<font color=\"red\">For your own dataset, the column numbers can vary. Change the number accordingly in the cell below at `y=ft_merged[,1088]` and `limits=c(-1e6,max(ft_merged[,1088])` </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f0443-0d6b-4cdb-befa-6c7a47799b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(ft_merged, \n",
    "       aes(x=`ATTRIBUTE_Injection_order`, \n",
    "           y=ft_merged[,1088])) + #paste the number from the previous cell output\n",
    "geom_point(size=2.5, alpha=0.9, \n",
    "           aes(color=as.factor(`ATTRIBUTE_Batch`), \n",
    "               shape = `ATTRIBUTE_Sample.Type`)) +\n",
    "geom_smooth(method = 'lm',na.rm = T) +  # to add a trend line\n",
    "scale_y_continuous(labels = scales::scientific,\n",
    "                   limits=c(-1e6,max(ft_merged[,1088]))) #paste the number from the previous cell output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bccb18-f976-42e0-b0d8-45655afbe833",
   "metadata": {},
   "source": [
    "Since,we do not observe a big drift in the intensity, we do not need to correct for intra-batch effect. But when one has QCs, and observe an intensity drift, you can perform within-batch correction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ecf92-b3dd-4f49-b47c-9f8e1bba18d9",
   "metadata": {},
   "source": [
    "<font color =\"red\"> Acceptable range for intensity drift?  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b5328-5691-4525-9443-4f6badb5280e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
